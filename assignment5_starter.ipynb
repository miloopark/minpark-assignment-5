{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcaee9bf-39fc-466a-a5d2-defe3d9df479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93ffa018-89de-47eb-a9e5-f6a8bc0f8b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8022feb9-6537-411f-8a5a-14d503ddd4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict_single(x) for x in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict_single(self, x):\n",
    "        distances = [self.compute_distance(x, x_train) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "\n",
    "    def compute_distance(self, X1, X2):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((X1 - X2) ** 2))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(X1 - X2))\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1a38c68-502c-45e8-af53-796f1c39296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(train, test):\n",
    "    # Dropping irrelevant columns: 'id', 'CustomerId', 'Surname'\n",
    "    train = train.drop(['id', 'CustomerId', 'Surname'], axis=1)\n",
    "    test = test.drop(['id', 'CustomerId', 'Surname'], axis=1)\n",
    "    \n",
    "    # Handle missing values for numerical and categorical columns\n",
    "    numerical_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "    categorical_cols = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n",
    "    \n",
    "    # Fill missing numerical columns with mean\n",
    "    for col in numerical_cols:\n",
    "        train[col].fillna(train[col].mean(), inplace=True)\n",
    "        test[col].fillna(test[col].mean(), inplace=True)\n",
    "    \n",
    "    # Fill missing categorical columns with most frequent value\n",
    "    for col in categorical_cols:\n",
    "        train[col].fillna(train[col].mode()[0], inplace=True)\n",
    "        test[col].fillna(test[col].mode()[0], inplace=True)\n",
    "    \n",
    "    # Encoding categorical variables\n",
    "    label_encodings = {}\n",
    "    for col in categorical_cols:\n",
    "        unique_vals = train[col].unique()\n",
    "        label_encodings[col] = {val: i for i, val in enumerate(unique_vals)}\n",
    "        train[col] = train[col].map(label_encodings[col])\n",
    "        test[col] = test[col].map(lambda x: label_encodings[col].get(x, -1))  # Handle unseen categories\n",
    "    \n",
    "    # Feature engineering: Balance to Salary ratio\n",
    "    train['Balance_to_Salary'] = train['Balance'] / (train['EstimatedSalary'] + 1)\n",
    "    test['Balance_to_Salary'] = test['Balance'] / (test['EstimatedSalary'] + 1)\n",
    "    \n",
    "    # Standardization of numerical features\n",
    "    for col in numerical_cols:\n",
    "        mean = train[col].mean()\n",
    "        std = train[col].std()\n",
    "        train[col] = (train[col] - mean) / std\n",
    "        test[col] = (test[col] - mean) / std\n",
    "    \n",
    "    # Split features and target\n",
    "    X_train = train.drop('Exited', axis=1).values\n",
    "    y_train = train['Exited'].values\n",
    "    X_test = test.values\n",
    "    \n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "153a3b69-c53e-4796-9d53-55ccd984a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_sample(X, y, knn, n_splits=3, sample_size=0.3):\n",
    "    n_samples = len(X)\n",
    "    sample_size = int(sample_size * n_samples)\n",
    "    indices = np.random.choice(n_samples, sample_size, replace=False)\n",
    "    \n",
    "    X_sample = X[indices]\n",
    "    y_sample = y[indices]\n",
    "    \n",
    "    fold_size = sample_size // n_splits\n",
    "    auc_scores = []\n",
    "\n",
    "    for fold in range(n_splits):\n",
    "        val_start = fold * fold_size\n",
    "        val_end = val_start + fold_size\n",
    "        \n",
    "        X_val = X_sample[val_start:val_end]\n",
    "        y_val = y_sample[val_start:val_end]\n",
    "        \n",
    "        X_train_fold = np.concatenate((X_sample[:val_start], X_sample[val_end:]))\n",
    "        y_train_fold = np.concatenate((y_sample[:val_start], y_sample[val_end:]))\n",
    "        \n",
    "        knn.fit(X_train_fold, y_train_fold)\n",
    "        y_val_pred = knn.predict(X_val)\n",
    "        \n",
    "        auc = compute_auc(y_val, y_val_pred)\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    return np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bb4ff97-ca72-4b37-953d-ea986de50d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(y_true, y_pred):\n",
    "    # Custom implementation to compute AUC based on true positives, false positives, etc.\n",
    "    sorted_indices = np.argsort(y_pred)\n",
    "    y_true_sorted = y_true[sorted_indices]\n",
    "    \n",
    "    total_positive = np.sum(y_true)\n",
    "    total_negative = len(y_true) - total_positive\n",
    "    tp, fp = 0, 0\n",
    "    auc = 0\n",
    "    for label in y_true_sorted:\n",
    "        if label == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "            auc += tp\n",
    "    \n",
    "    if total_positive * total_negative == 0:\n",
    "        return 0\n",
    "    \n",
    "    return auc / (total_positive * total_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f13086ba-3949-410a-9622-d991a3cb1963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 3, Metric: euclidean, AUC: 0.7603646264836792\n",
      "k: 3, Metric: manhattan, AUC: 0.7652486377825815\n",
      "k: 4, Metric: euclidean, AUC: 0.7441660075040418\n",
      "k: 4, Metric: manhattan, AUC: 0.7667308316820064\n",
      "k: 5, Metric: euclidean, AUC: 0.7509164771349983\n",
      "k: 5, Metric: manhattan, AUC: 0.7804733050370333\n",
      "k: 6, Metric: euclidean, AUC: 0.775610681826167\n",
      "k: 6, Metric: manhattan, AUC: 0.748368750068425\n",
      "Best k: 5, Best Distance Metric: manhattan, Best AUC: 0.7804733050370333\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('/mnt/data/train.csv')\n",
    "test_data = pd.read_csv('/mnt/data/test.csv')\n",
    "\n",
    "# Preprocess data\n",
    "X_train, y_train, X_test = preprocess_data(train_data, test_data)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "best_k = 3\n",
    "best_distance = 'euclidean'\n",
    "best_auc = 0\n",
    "\n",
    "for k in range(3, 7):\n",
    "    for metric in ['euclidean', 'manhattan']:\n",
    "        knn = KNN(k=k, distance_metric=metric)\n",
    "        auc_score = cross_validate_sample(X_train, y_train, knn, n_splits=3, sample_size=0.3)\n",
    "        print(f\"k: {k}, Metric: {metric}, AUC: {auc_score}\")\n",
    "        if auc_score > best_auc:\n",
    "            best_k = k\n",
    "            best_distance = metric\n",
    "            best_auc = auc_score\n",
    "\n",
    "print(f\"Best k: {best_k}, Best Distance Metric: {best_distance}, Best AUC: {best_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc32939c-1228-492d-ac25-2716cb89a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model and make predictions\n",
    "knn_final = KNN(k=best_k, distance_metric=best_distance)\n",
    "knn_final.fit(X_train, y_train)\n",
    "test_predictions = knn_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbeba595-0ae9-4af2-baed-3e7b3b4cafbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'submission.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the submission file\n",
    "test_data = pd.read_csv('test.csv')\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'Exited': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Predictions saved to 'submission.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
